
<!DOCTYPE html>

<html lang="en_US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Experiments and Examples &#8212; learnware 0.2.0.9 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_style.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Learnware Preparation and Uoloading" href="../workflows/upload.html" />
    <link rel="prev" title="Installation Guide" href="install.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en_US">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo1.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Home
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  GETTING STARTED:
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="quick.html">
   Quick Start
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="install.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Experiments and Examples
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  WORKFLOWS:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../workflows/upload.html">
   Learnware Preparation and Uploading
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../workflows/search.html">
   Learnware Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../workflows/reuse.html">
   Learnware Reuse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../workflows/client.html">
   Learnware Client
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  COMPONENTS:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../components/market.html">
   Market
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../components/learnware.html">
   Learnware &amp; Reuser
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../components/spec.html">
   Specification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../components/model.html">
   Model &amp; Container
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ADVANCED TOPICS:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/anchor.html">
   Anchor Learnware
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/evolve.html">
   Evolvable Specification
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  REFERENCES:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../references/api.html">
   API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../references/beimingwu.html">
   Beimingwu System
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../references/FAQ.html">
   FAQ
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ABOUTS:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../about/dev.html">
   For Developer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/changelog.html">
   Changelog
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../about/about.html">
   About us
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/start/exp.rst.txt"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.rst</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#environment">
   Environment
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tabular-data-experiments">
   Tabular Data Experiments
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#datasets">
     Datasets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#homogeneous-tabular-dataset">
     Homogeneous Tabular Dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#heterogeneous-tabular-dataset">
     Heterogeneous Tabular Dataset
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cross-feature-space-experiments">
       Cross Feature Space Experiments
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cross-task-experiments">
       Cross Task experiments
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#image-data-experiment">
   Image Data Experiment
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-data-experiment">
   Text Data Experiment
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Datasets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#results">
     Results
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#get-start-examples">
   Get Start Examples
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-examples">
     Text Examples
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-examples">
     Image Examples
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Experiments and Examples</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#environment">
   Environment
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tabular-data-experiments">
   Tabular Data Experiments
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#datasets">
     Datasets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#homogeneous-tabular-dataset">
     Homogeneous Tabular Dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#heterogeneous-tabular-dataset">
     Heterogeneous Tabular Dataset
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cross-feature-space-experiments">
       Cross Feature Space Experiments
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cross-task-experiments">
       Cross Task experiments
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#image-data-experiment">
   Image Data Experiment
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-data-experiment">
   Text Data Experiment
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Datasets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#results">
     Results
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#get-start-examples">
   Get Start Examples
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-examples">
     Text Examples
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-examples">
     Image Examples
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="experiments-and-examples">
<h1>Experiments and Examples<a class="headerlink" href="#experiments-and-examples" title="Permalink to this headline">#</a></h1>
<p>This chapter will introduce related experiments to illustrate the search and reuse performance of our learnware system.</p>
<section id="environment">
<h2>Environment<a class="headerlink" href="#environment" title="Permalink to this headline">#</a></h2>
<p>For all experiments, we used a single linux server. Details on the specifications are listed in the table below. All processors were used for training and evaluating.</p>
<table class="table">
<colgroup>
<col style="width: 28%" />
<col style="width: 28%" />
<col style="width: 44%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>System</p></th>
<th class="head"><p>GPU</p></th>
<th class="head"><p>CPU</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Ubuntu 20.04.4 LTS</p></td>
<td><p>Nvidia Tesla V100S</p></td>
<td><p>Intel(R) Xeon(R) Gold 6240R</p></td>
</tr>
</tbody>
</table>
</section>
<section id="tabular-data-experiments">
<h2>Tabular Data Experiments<a class="headerlink" href="#tabular-data-experiments" title="Permalink to this headline">#</a></h2>
<section id="datasets">
<h3>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">#</a></h3>
<p>Our study involved three public datasets in the sales forecasting field: <a class="reference external" href="https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data">Predict Future Sales (PFS)</a>,
<a class="reference external" href="https://www.kaggle.com/competitions/m5-forecasting-accuracy/data">M5 Forecasting (M5)</a> and <a class="reference external" href="https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting/data">Corporacion</a>.
We applied various pre-processing methods to these datasets to enhance the richness of the data.
After pre-processing, we first divided each dataset by store and then split the data for each store into training and test sets. Specifically:</p>
<ul class="simple">
<li><p>For PFS, the test set consisted of the last month’s data from each store.</p></li>
<li><p>For M5, we designated the final 28 days’ data from each store as the test set.</p></li>
<li><p>For Corporacion, the test set was composed of the last 16 days of data from each store.</p></li>
</ul>
<p>In the submitting stage, the Corporacion dataset’s 55 stores are regarded as 165 uploaders, each employing one of three different feature engineering methods.
For the PFS dataset, 100 uploaders are established, each using one of two feature engineering approaches.
These uploaders then utilize their respective stores’ training data to develop LightGBM models.
As a result, the learnware market comprises 265 learnwares, derived from five types of feature spaces and two types of label spaces</p>
<p>Based on the specific design of user tasks, our experiments were primarily categorized into two types:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">homogeneous</span> <span class="pre">experiments</span></code> are designed to evaluate performance when users can reuse learnwares in the learnware market that have the same feature space as their tasks(homogeneous learnwares).
This contributes to showing the effectiveness of using learnwares that align closely with the user’s specific requirements.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">heterogeneous</span> <span class="pre">experiments</span></code> aim to evaluate the performance of identifying and reusing helpful heterogeneous learnwares in situations where
no available learnwares match the feature space of the user’s task. This helps to highlight the potential of learnwares for applications beyond their original purpose.</p></li>
</ul>
</section>
<section id="homogeneous-tabular-dataset">
<h3>Homogeneous Tabular Dataset<a class="headerlink" href="#homogeneous-tabular-dataset" title="Permalink to this headline">#</a></h3>
<p>For homogeneous experiments, the 55 stores in the Corporacion dataset act as 55 users, each applying one feature engineering method,
and using the test data from their respective store as user data. These users can then search for homogeneous learnwares in the market with the same feature spaces as their tasks.</p>
<p>The Mean Squared Error (MSE) of search and reuse across all users is presented in the table below:</p>
<table class="table">
<colgroup>
<col style="width: 63%" />
<col style="width: 38%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Setting</p></th>
<th class="head"><p>MSE</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Mean in Market (Single)</p></td>
<td><p>0.331</p></td>
</tr>
<tr class="row-odd"><td><p>Best in Market (Single)</p></td>
<td><p>0.151</p></td>
</tr>
<tr class="row-even"><td><p>Top-1 Reuse (Single)</p></td>
<td><p>0.280</p></td>
</tr>
<tr class="row-odd"><td><p>Job Selector Reuse (Multiple)</p></td>
<td><p>0.274</p></td>
</tr>
<tr class="row-even"><td><p>Average Ensemble Reuse (Multiple)</p></td>
<td><p>0.267</p></td>
</tr>
</tbody>
</table>
<p>When users have both test data and limited training data derived from their original data, reusing single or multiple searched learnwares from the market can often yield
better results than training models from scratch on limited training data. We present the change curves in MSE for the user’s self-trained model, as well as for the Feature Augmentation single learnware reuse method and the Ensemble Pruning multiple learnware reuse method.
These curves display their performance on the user’s test data as the amount of labeled training data increases.
The average results across 55 users are depicted in the figure below:</p>
<img alt="Table Homo Limited Labeled Data" class="align-center" src="../_images/table_homo_labeled.png" />
<p>From the figure, it’s evident that when users have limited training data, the performance of reusing single/multiple table learnwares is superior to that of the user’s own model.
This emphasizes the benefit of learnware reuse in significantly reducing the need for extensive training data and achieving enhanced results when available user training data is limited.</p>
</section>
<section id="heterogeneous-tabular-dataset">
<h3>Heterogeneous Tabular Dataset<a class="headerlink" href="#heterogeneous-tabular-dataset" title="Permalink to this headline">#</a></h3>
<p>In heterogeneous experiments, the learnware market would recommend helpful heterogeneous learnwares with different feature spaces with
the user tasks. Based on whether there are learnwares in the market that handle tasks similar to the user’s task, the experiments can be further subdivided into the following two types:</p>
<section id="cross-feature-space-experiments">
<h4>Cross Feature Space Experiments<a class="headerlink" href="#cross-feature-space-experiments" title="Permalink to this headline">#</a></h4>
<p>We designate the 41 stores in the PFS dataset as users, creating their user data with an alternative feature engineering approach that varies from the methods employed by learnwares in the market.
Consequently, while the market’s learnwares from the PFS dataset undertake tasks very similar to our users, the feature spaces do not match exactly. In this experimental configuration,
we tested various heterogeneous learnware reuse methods (without using user’s labeled data) and compared them to the user’s self-trained model based on a small amount of training data.
The average MSE performance across 41 users are as follows:</p>
<table class="table">
<colgroup>
<col style="width: 63%" />
<col style="width: 38%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Setting</p></th>
<th class="head"><p>MSE</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Mean in Market (Single)</p></td>
<td><p>1.459</p></td>
</tr>
<tr class="row-odd"><td><p>Best in Market (Single)</p></td>
<td><p>1.226</p></td>
</tr>
<tr class="row-even"><td><p>Top-1 Reuse (Single)</p></td>
<td><p>1.407</p></td>
</tr>
<tr class="row-odd"><td><p>Average Ensemble Reuse (Multiple)</p></td>
<td><p>1.312</p></td>
</tr>
<tr class="row-even"><td><p>User model with 50 labeled data</p></td>
<td><p>1.267</p></td>
</tr>
</tbody>
</table>
<p>From the results, it is noticeable that the learnware market still perform quite well even when users lack labeled data,
provided it includes learnwares addressing tasks that are similar but not identical to the user’s.
In these instances, the market’s effectiveness can match or even rival scenarios where users have access to a limited quantity of labeled data.</p>
</section>
<section id="cross-task-experiments">
<h4>Cross Task experiments<a class="headerlink" href="#cross-task-experiments" title="Permalink to this headline">#</a></h4>
<p>Here we have chosen the 10 stores from the M5 dataset to act as users. Although the broad task of sales forecasting is similar to the tasks addressed by the learnwares in the market,
there are no learnwares available that directly cater to the M5 sales forecasting requirements. All learnwares show variations in both feature and label spaces compared to the tasks of M5 users.
We present the change curves in RMSE for the user’s self-trained model and several learnware reuse methods.
These curves display their performance on the user’s test data as the amount of labeled training data increases.
The average results across 10 users are depicted in the figure below:</p>
<img alt="Table Hetero Limited Labeled Data" class="align-center" src="../_images/table_hetero_labeled.png" />
<p>We can observe that heterogeneous learnwares are beneficial when there’s a limited amount of the user’s labeled training data available,
aiding in better alignment with the user’s specific task. This underscores the potential of learnwares to be applied to tasks beyond their original purpose.</p>
</section>
</section>
</section>
<section id="image-data-experiment">
<h2>Image Data Experiment<a class="headerlink" href="#image-data-experiment" title="Permalink to this headline">#</a></h2>
<p>For the CIFAR-10 dataset, we sampled the training set unevenly by category and constructed unbalanced training datasets for the 50 learnwares that contained only some of the categories. This makes it unlikely that there exists any learnware in the learnware market that can accurately handle all categories of data; only the learnware whose training data is closest to the data distribution of the target task is likely to perform well on the target task. Specifically, the probability of each category being sampled obeys a random multinomial distribution, with a non-zero probability of sampling on only 4 categories, and the sampling ratio is 0.4: 0.4: 0.1: 0.1. Ultimately, the training set for each learnware contains 12,000 samples covering the data of 4 categories in CIFAR-10.</p>
<p>We constructed 50 target tasks using data from the test set of CIFAR-10. Similar to constructing the training set for the learnwares, in order to allow for some variation between tasks, we sampled the test set unevenly. Specifically, the probability of each category being sampled obeys a random multinomial distribution, with non-zero sampling probability on 6 categories, and the sampling ratio is 0.3: 0.3: 0.1: 0.1: 0.1: 0.1. Ultimately, each target task contains 3000 samples covering the data of 6 categories in CIFAR-10.</p>
<p>With this experimental setup, we evaluated the performance of RKME Image using 1 - Accuracy as the loss.</p>
<table class="table">
<colgroup>
<col style="width: 63%" />
<col style="width: 38%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Setting</p></th>
<th class="head"><p>Accuracy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Mean in Market (Single)</p></td>
<td><p>0.655</p></td>
</tr>
<tr class="row-odd"><td><p>Best in Market (Single)</p></td>
<td><p>0.304</p></td>
</tr>
<tr class="row-even"><td><p>Top-1 Reuse (Single)</p></td>
<td><p>0.406</p></td>
</tr>
<tr class="row-odd"><td><p>Job Selector Reuse (Multiple)</p></td>
<td><p>0.406</p></td>
</tr>
<tr class="row-even"><td><p>Average Ensemble Reuse (Multiple)</p></td>
<td><p>0.310</p></td>
</tr>
</tbody>
</table>
<p>In some specific settings, the user will have a small number of labelled samples. In such settings, learning the weight of selected learnwares on a limited number of labelled samples can result in a better performance than training directly on a limited number of labelled samples.</p>
<img alt="../_images/image_labeled.svg" class="align-center" src="../_images/image_labeled.svg" /></section>
<section id="text-data-experiment">
<h2>Text Data Experiment<a class="headerlink" href="#text-data-experiment" title="Permalink to this headline">#</a></h2>
<section id="id1">
<h3>Datasets<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>We conducted experiments on the widely used text benchmark dataset: <a class="reference external" href="http://qwone.com/~jason/20Newsgroups/">20-newsgroup</a>.
20-newsgroup is a renowned text classification benchmark with a hierarchical structure, featuring 5 superclasses {comp, rec, sci, talk, misc}.</p>
<p>In the submitting stage, we enumerated all combinations of three superclasses from the five available, randomly sampling 50% of each combination from the training set to create datasets for 50 uploaders.</p>
<p>In the deploying stage, we considered all combinations of two superclasses out of the five, selecting all data for each combination from the testing set as a test dataset for one user. This resulted in 10 users.
The user’s own training data was generated using the same sampling procedure as the user test data, despite originating from the training dataset.</p>
<p>Model training comprised two parts: the first part involved training a tfidf feature extractor, and the second part used the extracted text feature vectors to train a naive Bayes classifier.</p>
<p>Our experiments comprises two components:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">unlabeled_text_example</span></code> is designed to evaluate performance when users possess only testing data, searching and reusing learnware available in the market.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">labeled_text_example</span></code> aims to assess performance when users have both testing and limited training data, searching and reusing learnware directly from the market instead of training a model from scratch. This helps determine the amount of training data saved for the user.</p></li>
</ul>
</section>
<section id="results">
<h3>Results<a class="headerlink" href="#results" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">unlabeled_text_example</span></code>:</p></li>
</ul>
<p>The table below presents the mean accuracy of search and reuse across all users:</p>
<table class="table">
<colgroup>
<col style="width: 63%" />
<col style="width: 38%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Setting</p></th>
<th class="head"><p>Accuracy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Mean in Market (Single)</p></td>
<td><p>0.507</p></td>
</tr>
<tr class="row-odd"><td><p>Best in Market (Single)</p></td>
<td><p>0.859</p></td>
</tr>
<tr class="row-even"><td><p>Top-1 Reuse (Single)</p></td>
<td><p>0.846</p></td>
</tr>
<tr class="row-odd"><td><p>Job Selector Reuse (Multiple)</p></td>
<td><p>0.845</p></td>
</tr>
<tr class="row-even"><td><p>Average Ensemble Reuse (Multiple)</p></td>
<td><p>0.862</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">labeled_text_example</span></code>:</p></li>
</ul>
<p>We present the change curves in classification error rates for both the user’s self-trained model and the multiple learnware reuse(EnsemblePrune), showcasing their performance on the user’s test data as the user’s training data increases. The average results across 10 users are depicted below:</p>
<img alt="Results on Text Experimental Scenario" class="align-center" src="../_images/text_labeled.svg" /><p>From the figure above, it is evident that when the user’s own training data is limited, the performance of multiple learnware reuse surpasses that of the user’s own model. As the user’s training data grows, it is expected that the user’s model will eventually outperform the learnware reuse. This underscores the value of reusing learnware to significantly conserve training data and achieve superior performance when user training data is limited.</p>
</section>
</section>
<section id="get-start-examples">
<h2>Get Start Examples<a class="headerlink" href="#get-start-examples" title="Permalink to this headline">#</a></h2>
<p>Examples for <cite>Tabular, Text</cite> and <cite>Image</cite> data sets are available at <a class="reference external" href="https://github.com/Learnware-LAMDA/Learnware/tree/main/examples">Learnware Examples</a>. You can run { main.py } directly to reproduce related experiments.
We utilize the <cite>fire</cite> module to construct our experiments.</p>
<section id="text-examples">
<h3>Text Examples<a class="headerlink" href="#text-examples" title="Permalink to this headline">#</a></h3>
<p>You can execute the experiment with the following commands:</p>
<ul class="simple">
<li><p><cite>python main.py unlabeled_text_example</cite>: Executes the unlabeled_text_example experiment; the results will be printed in the terminal.</p></li>
<li><p><cite>python main.py labeled_text_example</cite>: Executes the labeled_text_example experiment; result curves will be automatically saved in the <cite>figs</cite> directory.</p></li>
</ul>
</section>
<section id="image-examples">
<h3>Image Examples<a class="headerlink" href="#image-examples" title="Permalink to this headline">#</a></h3>
<p>You can execute the experiment with the following commands:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>workflow.py<span class="w"> </span>image_example
</pre></div>
</div>
</section>
</section>
</section>


              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="install.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Installation Guide</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../workflows/upload.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Learnware Preparation and Uoloading</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By LAMDA Group<br/>
  
      &copy; Copyright 2023, LAMDA Group.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>