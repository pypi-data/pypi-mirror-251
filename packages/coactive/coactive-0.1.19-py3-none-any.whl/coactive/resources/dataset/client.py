# This file was auto-generated by Fern from our API Definition.

import typing
import urllib.parse
from json.decoder import JSONDecodeError

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.jsonable_encoder import jsonable_encoder
from ...core.remove_none_from_dict import remove_none_from_dict
from ...errors.bad_request_error import BadRequestError
from ...errors.not_found_error import NotFoundError
from ...errors.unprocessable_entity_error import UnprocessableEntityError
from ...types.add_asset_item import AddAssetItem
from ...types.dataset import Dataset
from ...types.error_response import ErrorResponse
from ...types.http_validation_error import HttpValidationError
from ...types.paged_datasets import PagedDatasets
from ...types.paged_images import PagedImages
from ...types.paged_videos import PagedVideos
from ...types.update_asset_metadata_item import UpdateAssetMetadataItem

try:
    import pydantic.v1 as pydantic  # type: ignore
except ImportError:
    import pydantic  # type: ignore

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class DatasetClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list(self, *, offset: typing.Optional[int] = None, limit: typing.Optional[int] = None) -> PagedDatasets:
        """
        Get all datasets in a paginated list

        Parameters:
            - offset: typing.Optional[int]. Starting index to return

            - limit: typing.Optional[int]. Max number of items to return
        ---
        from coactive.client import Coactive

        client = Coactive(
            token="YOUR_TOKEN",
        )
        client.dataset.list()
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/datasets"),
            params=remove_none_from_dict({"offset": offset, "limit": limit}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PagedDatasets, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def create(
        self,
        *,
        name: str,
        description: typing.Optional[str] = OMIT,
        data_path: typing.Optional[str] = OMIT,
        csv_path: typing.Optional[str] = OMIT,
        credentials_id: typing.Optional[str] = OMIT,
    ) -> Dataset:
        """
        Create a new dataset

        Parameters:
            - name: str. The name of the dataset

            - description: typing.Optional[str]. The description of the dataset

            - data_path: typing.Optional[str]. An S3 or GCS path prefix for all images and videos to add to the dataset

            - csv_path: typing.Optional[str]. A path to a previously uploaded CSV file containing data paths

            - credentials_id: typing.Optional[str]. The id of the credentials to use to access protected data
        ---
        from coactive.client import Coactive

        client = Coactive(
            token="YOUR_TOKEN",
        )
        client.dataset.create(
            name="GameOfThrones",
            description="A dataset containing screenshots and clips from the tv show Game of Thrones",
            data_path="s3://your-s3-bucket/path/prefix",
            csv_path="path/to/file.csv",
            credentials_id="382cc760-8e8e-4b97-abab-84438282cb9a",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"name": name}
        if description is not OMIT:
            _request["description"] = description
        if data_path is not OMIT:
            _request["dataPath"] = data_path
        if csv_path is not OMIT:
            _request["csvPath"] = csv_path
        if credentials_id is not OMIT:
            _request["credentialsId"] = credentials_id
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/datasets"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
        if _response.status_code == 400:
            raise BadRequestError(pydantic.parse_obj_as(ErrorResponse, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get(self, dataset_id: str) -> Dataset:
        """
        Get dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset
        ---
        from coactive.client import Coactive

        client = Coactive(
            token="YOUR_TOKEN",
        )
        client.dataset.get(
            dataset_id="dataset-id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def delete(self, dataset_id: str) -> typing.Any:
        """
        Delete dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset
        """
        _response = self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update(
        self, dataset_id: str, *, name: typing.Optional[str] = OMIT, description: typing.Optional[str] = OMIT
    ) -> Dataset:
        """
        Update dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset

            - name: typing.Optional[str]. New name for the dataset

            - description: typing.Optional[str]. New description for the dataset
        ---
        from coactive.client import Coactive

        client = Coactive(
            token="YOUR_TOKEN",
        )
        client.dataset.update(
            dataset_id="dataset-id",
            name="GameOfThrones",
            description="A dataset containing screenshots and clips from the tv show Game of Thrones",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if name is not OMIT:
            _request["name"] = name
        if description is not OMIT:
            _request["description"] = description
        _response = self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
        if _response.status_code == 400:
            raise BadRequestError(pydantic.parse_obj_as(ErrorResponse, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_images(
        self, dataset_id: str, *, offset: typing.Optional[int] = None, limit: typing.Optional[int] = None
    ) -> PagedImages:
        """
        Get images in a dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset

            - offset: typing.Optional[int]. Starting index to return

            - limit: typing.Optional[int]. Max number of items to return
        ---
        from coactive.client import Coactive

        client = Coactive(
            token="YOUR_TOKEN",
        )
        client.dataset.get_images(
            dataset_id="dataset-id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}/images"),
            params=remove_none_from_dict({"offset": offset, "limit": limit}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PagedImages, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_videos(
        self, dataset_id: str, *, offset: typing.Optional[int] = None, limit: typing.Optional[int] = None
    ) -> PagedVideos:
        """
        Get videos in a dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset

            - offset: typing.Optional[int]. Starting index to return

            - limit: typing.Optional[int]. Max number of items to return
        ---
        from coactive.client import Coactive

        client = Coactive(
            token="YOUR_TOKEN",
        )
        client.dataset.get_videos(
            dataset_id="dataset-id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}/videos"),
            params=remove_none_from_dict({"offset": offset, "limit": limit}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PagedVideos, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def add_assets(
        self,
        dataset_id: str,
        *,
        items: typing.Optional[typing.List[AddAssetItem]] = OMIT,
        data_path: typing.Optional[str] = OMIT,
        csv_path: typing.Optional[str] = OMIT,
    ) -> Dataset:
        """
        Add images and/or videos to an existing dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset

            - items: typing.Optional[typing.List[AddAssetItem]]. A list of assets to add with optional metadata

            - data_path: typing.Optional[str]. A S3 path prefix for all images and videos to add to the dataset

            - csv_path: typing.Optional[str]. A path to a previously uploaded CSV file containing data paths
        ---
        from coactive import AddAssetItem
        from coactive.client import Coactive

        client = Coactive(
            token="YOUR_TOKEN",
        )
        client.dataset.add_assets(
            dataset_id="dataset-id",
            items=[
                AddAssetItem(
                    path="s3://your-s3-bucket/path/to/img.png",
                )
            ],
            data_path="s3://your-s3-bucket/path/prefix",
            csv_path="path/to/file.csv",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if items is not OMIT:
            _request["items"] = items
        if data_path is not OMIT:
            _request["dataPath"] = data_path
        if csv_path is not OMIT:
            _request["csvPath"] = csv_path
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}/assets"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def update_asset_metadata(
        self, dataset_id: str, *, items: typing.Optional[typing.List[UpdateAssetMetadataItem]] = OMIT
    ) -> Dataset:
        """
        Update image and/or video metadata in an existing dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset

            - items: typing.Optional[typing.List[UpdateAssetMetadataItem]]. A list of assets to add with metadata
        ---
        from coactive import UpdateAssetMetadataItem
        from coactive.client import Coactive

        client = Coactive(
            token="YOUR_TOKEN",
        )
        client.dataset.update_asset_metadata(
            dataset_id="dataset-id",
            items=[
                UpdateAssetMetadataItem(
                    path="s3://your-s3-bucket/path/to/img.png",
                    metadata={},
                )
            ],
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if items is not OMIT:
            _request["items"] = items
        _response = self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}/assets_metadata"
            ),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncDatasetClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list(self, *, offset: typing.Optional[int] = None, limit: typing.Optional[int] = None) -> PagedDatasets:
        """
        Get all datasets in a paginated list

        Parameters:
            - offset: typing.Optional[int]. Starting index to return

            - limit: typing.Optional[int]. Max number of items to return
        ---
        from coactive.client import AsyncCoactive

        client = AsyncCoactive(
            token="YOUR_TOKEN",
        )
        await client.dataset.list()
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/datasets"),
            params=remove_none_from_dict({"offset": offset, "limit": limit}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PagedDatasets, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def create(
        self,
        *,
        name: str,
        description: typing.Optional[str] = OMIT,
        data_path: typing.Optional[str] = OMIT,
        csv_path: typing.Optional[str] = OMIT,
        credentials_id: typing.Optional[str] = OMIT,
    ) -> Dataset:
        """
        Create a new dataset

        Parameters:
            - name: str. The name of the dataset

            - description: typing.Optional[str]. The description of the dataset

            - data_path: typing.Optional[str]. An S3 or GCS path prefix for all images and videos to add to the dataset

            - csv_path: typing.Optional[str]. A path to a previously uploaded CSV file containing data paths

            - credentials_id: typing.Optional[str]. The id of the credentials to use to access protected data
        ---
        from coactive.client import AsyncCoactive

        client = AsyncCoactive(
            token="YOUR_TOKEN",
        )
        await client.dataset.create(
            name="GameOfThrones",
            description="A dataset containing screenshots and clips from the tv show Game of Thrones",
            data_path="s3://your-s3-bucket/path/prefix",
            csv_path="path/to/file.csv",
            credentials_id="382cc760-8e8e-4b97-abab-84438282cb9a",
        )
        """
        _request: typing.Dict[str, typing.Any] = {"name": name}
        if description is not OMIT:
            _request["description"] = description
        if data_path is not OMIT:
            _request["dataPath"] = data_path
        if csv_path is not OMIT:
            _request["csvPath"] = csv_path
        if credentials_id is not OMIT:
            _request["credentialsId"] = credentials_id
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", "api/v1/datasets"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
        if _response.status_code == 400:
            raise BadRequestError(pydantic.parse_obj_as(ErrorResponse, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get(self, dataset_id: str) -> Dataset:
        """
        Get dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset
        ---
        from coactive.client import AsyncCoactive

        client = AsyncCoactive(
            token="YOUR_TOKEN",
        )
        await client.dataset.get(
            dataset_id="dataset-id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def delete(self, dataset_id: str) -> typing.Any:
        """
        Delete dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset
        """
        _response = await self._client_wrapper.httpx_client.request(
            "DELETE",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.Any, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update(
        self, dataset_id: str, *, name: typing.Optional[str] = OMIT, description: typing.Optional[str] = OMIT
    ) -> Dataset:
        """
        Update dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset

            - name: typing.Optional[str]. New name for the dataset

            - description: typing.Optional[str]. New description for the dataset
        ---
        from coactive.client import AsyncCoactive

        client = AsyncCoactive(
            token="YOUR_TOKEN",
        )
        await client.dataset.update(
            dataset_id="dataset-id",
            name="GameOfThrones",
            description="A dataset containing screenshots and clips from the tv show Game of Thrones",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if name is not OMIT:
            _request["name"] = name
        if description is not OMIT:
            _request["description"] = description
        _response = await self._client_wrapper.httpx_client.request(
            "PATCH",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
        if _response.status_code == 400:
            raise BadRequestError(pydantic.parse_obj_as(ErrorResponse, _response.json()))  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_images(
        self, dataset_id: str, *, offset: typing.Optional[int] = None, limit: typing.Optional[int] = None
    ) -> PagedImages:
        """
        Get images in a dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset

            - offset: typing.Optional[int]. Starting index to return

            - limit: typing.Optional[int]. Max number of items to return
        ---
        from coactive.client import AsyncCoactive

        client = AsyncCoactive(
            token="YOUR_TOKEN",
        )
        await client.dataset.get_images(
            dataset_id="dataset-id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}/images"),
            params=remove_none_from_dict({"offset": offset, "limit": limit}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PagedImages, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_videos(
        self, dataset_id: str, *, offset: typing.Optional[int] = None, limit: typing.Optional[int] = None
    ) -> PagedVideos:
        """
        Get videos in a dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset

            - offset: typing.Optional[int]. Starting index to return

            - limit: typing.Optional[int]. Max number of items to return
        ---
        from coactive.client import AsyncCoactive

        client = AsyncCoactive(
            token="YOUR_TOKEN",
        )
        await client.dataset.get_videos(
            dataset_id="dataset-id",
        )
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}/videos"),
            params=remove_none_from_dict({"offset": offset, "limit": limit}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(PagedVideos, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def add_assets(
        self,
        dataset_id: str,
        *,
        items: typing.Optional[typing.List[AddAssetItem]] = OMIT,
        data_path: typing.Optional[str] = OMIT,
        csv_path: typing.Optional[str] = OMIT,
    ) -> Dataset:
        """
        Add images and/or videos to an existing dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset

            - items: typing.Optional[typing.List[AddAssetItem]]. A list of assets to add with optional metadata

            - data_path: typing.Optional[str]. A S3 path prefix for all images and videos to add to the dataset

            - csv_path: typing.Optional[str]. A path to a previously uploaded CSV file containing data paths
        ---
        from coactive import AddAssetItem
        from coactive.client import AsyncCoactive

        client = AsyncCoactive(
            token="YOUR_TOKEN",
        )
        await client.dataset.add_assets(
            dataset_id="dataset-id",
            items=[
                AddAssetItem(
                    path="s3://your-s3-bucket/path/to/img.png",
                )
            ],
            data_path="s3://your-s3-bucket/path/prefix",
            csv_path="path/to/file.csv",
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if items is not OMIT:
            _request["items"] = items
        if data_path is not OMIT:
            _request["dataPath"] = data_path
        if csv_path is not OMIT:
            _request["csvPath"] = csv_path
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}/assets"),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def update_asset_metadata(
        self, dataset_id: str, *, items: typing.Optional[typing.List[UpdateAssetMetadataItem]] = OMIT
    ) -> Dataset:
        """
        Update image and/or video metadata in an existing dataset

        Parameters:
            - dataset_id: str. The unique identifier for the dataset

            - items: typing.Optional[typing.List[UpdateAssetMetadataItem]]. A list of assets to add with metadata
        ---
        from coactive import UpdateAssetMetadataItem
        from coactive.client import AsyncCoactive

        client = AsyncCoactive(
            token="YOUR_TOKEN",
        )
        await client.dataset.update_asset_metadata(
            dataset_id="dataset-id",
            items=[
                UpdateAssetMetadataItem(
                    path="s3://your-s3-bucket/path/to/img.png",
                    metadata={},
                )
            ],
        )
        """
        _request: typing.Dict[str, typing.Any] = {}
        if items is not OMIT:
            _request["items"] = items
        _response = await self._client_wrapper.httpx_client.request(
            "POST",
            urllib.parse.urljoin(
                f"{self._client_wrapper.get_base_url()}/", f"api/v1/datasets/{dataset_id}/assets_metadata"
            ),
            json=jsonable_encoder(_request),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(Dataset, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
