from abc import abstractmethod
from typing import List, Mapping, Optional, Any
from langchain.llms.base import LLM
from langchain_core.pydantic_v1 import BaseModel, Field

class BaseMedpromptLLM(LLM):

    hosted_url:str = Field(None, alias='hosted_url') #! Alias is important when inheriting from LLM
    model_name:str = Field(None, alias='model_name')
    params: Mapping[str, Any] = Field(None, alias='params')

    backend:                Optional[str]   = 'medprompt'
    temperature:            Optional[float] = 0.1
    top_p:                  Optional[float] = 0.8
    top_k:                  Optional[int]   = 40
    n_batch:                Optional[int]   = 8
    n_threads:              Optional[int]   = 4
    n_predict:              Optional[int]   = 256
    max_output_tokens:      Optional[int]   = 512
    repeat_last_n:          Optional[int]   = 64
    repeat_penalty:         Optional[float] = 1.18


    def __init__(self, hosted_url: str, model_name:str, **kwargs):
        super().__init__(**kwargs)
        self.hosted_url = hosted_url
        self.model_name = model_name
        self.params = {
            **self._get_model_default_parameters,
            **kwargs
        }


    @property
    def _get_model_default_parameters(self):
        return {
            "max_output_tokens": self.max_output_tokens,
            "n_predict": self.n_predict,
            "top_k": self.top_k,
            "top_p": self.top_p,
            "temperature": self.temperature,
            "n_batch": self.n_batch,
            "repeat_penalty": self.repeat_penalty,
            "repeat_last_n": self.repeat_last_n,
        }

    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        """
        Get all the identifying parameters
        """
        return {
            'model_name' : self._model_name,
            'hosted_url' : self._hosted_url,
            'model_parameters': self._get_model_default_parameters
        }

    @property
    def _llm_type(self) -> str:
        return "medprompt"

    @abstractmethod
    def _call(self, prompt: str, stop: Optional[List[str]] = None, **kwargs) -> str:
        """
        Args:
            prompt: The prompt to pass into the model.
            stop: A list of strings to stop generation when encountered

        Returns:
            The string generated by the model
        """

        pass